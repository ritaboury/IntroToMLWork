{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92778525",
      "metadata": {
        "id": "92778525"
      },
      "source": [
        "<font size=\"+3\"><b>Linear Models and Validation Metrics</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "<font color='Blue'>In this assignment, you will need to write code that uses linear models to perform classification and regression tasks. You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment.</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7c6de86",
      "metadata": {
        "id": "f7c6de86"
      },
      "source": [
        "# **Part 1: Classification (14.5 marks total)**\n",
        "\n",
        "You have been asked to develop code that can help the user determine if the email they have received is spam or not. Following the machine learning workflow described in class, write the relevant code in each of the steps below:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e3c6fc8",
      "metadata": {
        "id": "7e3c6fc8"
      },
      "source": [
        "## **Step 0:** Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33f86925",
      "metadata": {
        "id": "33f86925"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f9d33a8",
      "metadata": {
        "id": "5f9d33a8"
      },
      "source": [
        "## **Step 1:** Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
        "\n",
        "Use the yellowbrick function `load_spam()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33583c67",
      "metadata": {
        "id": "33583c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c21a746-4f4e-46ad-e2ed-eba72041c1e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X: 262200\n",
            "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
            "Size of y: 4600\n",
            "Type of y: <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "# Import spam dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_spam\n",
        "\n",
        "# Load spam dataset into the feature matrix X and target vector y\n",
        "X, y = load_spam()\n",
        "\n",
        "# Print size and type of X and y\n",
        "print(\"Size of X:\", X.size)\n",
        "print(\"Type of X:\", type(X))\n",
        "print(\"Size of y:\", y.size)\n",
        "print(\"Type of y:\", type(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "156db208",
      "metadata": {
        "id": "156db208"
      },
      "source": [
        "## **Step 2:** Data Processing (1.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e7204f5",
      "metadata": {
        "id": "4e7204f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "918df977-c034-4711-fb2e-531d4b7181b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_freq_make                False\n",
            "word_freq_address             False\n",
            "word_freq_all                 False\n",
            "word_freq_3d                  False\n",
            "word_freq_our                 False\n",
            "word_freq_over                False\n",
            "word_freq_remove              False\n",
            "word_freq_internet            False\n",
            "word_freq_order               False\n",
            "word_freq_mail                False\n",
            "word_freq_receive             False\n",
            "word_freq_will                False\n",
            "word_freq_people              False\n",
            "word_freq_report              False\n",
            "word_freq_addresses           False\n",
            "word_freq_free                False\n",
            "word_freq_business            False\n",
            "word_freq_email               False\n",
            "word_freq_you                 False\n",
            "word_freq_credit              False\n",
            "word_freq_your                False\n",
            "word_freq_font                False\n",
            "word_freq_000                 False\n",
            "word_freq_money               False\n",
            "word_freq_hp                  False\n",
            "word_freq_hpl                 False\n",
            "word_freq_george              False\n",
            "word_freq_650                 False\n",
            "word_freq_lab                 False\n",
            "word_freq_labs                False\n",
            "word_freq_telnet              False\n",
            "word_freq_857                 False\n",
            "word_freq_data                False\n",
            "word_freq_415                 False\n",
            "word_freq_85                  False\n",
            "word_freq_technology          False\n",
            "word_freq_1999                False\n",
            "word_freq_parts               False\n",
            "word_freq_pm                  False\n",
            "word_freq_direct              False\n",
            "word_freq_cs                  False\n",
            "word_freq_meeting             False\n",
            "word_freq_original            False\n",
            "word_freq_project             False\n",
            "word_freq_re                  False\n",
            "word_freq_edu                 False\n",
            "word_freq_table               False\n",
            "word_freq_conference          False\n",
            "char_freq_;                   False\n",
            "char_freq_(                   False\n",
            "char_freq_[                   False\n",
            "char_freq_!                   False\n",
            "char_freq_$                   False\n",
            "char_freq_#                   False\n",
            "capital_run_length_average    False\n",
            "capital_run_length_longest    False\n",
            "capital_run_length_total      False\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "# Check if there are any missing values and fill them in if necessary\n",
        "missing_values = X.isnull().any()\n",
        "print(missing_values)\n",
        "\n",
        "# All values are False (no values are missing from any column) so no method to fill-in is necessary\n",
        "# If a number was missing, it could be filled with 0 using the line below\n",
        "# X.fillna(0, inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a489285a",
      "metadata": {
        "id": "a489285a"
      },
      "source": [
        "For this task, we want to test if the linear model would still work if we used less data. Use the `train_test_split` function from sklearn to create a new feature matrix named `X_small` and a new target vector named `y_small` that contain **5%** of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9bc4a23",
      "metadata": {
        "id": "f9bc4a23"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Create X_small and y_small\n",
        "# Since the order is usually X_train, X_test, y_train, y_test, the line below would treat X_small and y_small as \"test\" sets with test_size = 0.05\n",
        "_ , X_small, _ , y_small = train_test_split(X, y, test_size = 0.05, random_state = 42)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70e6c46f",
      "metadata": {
        "id": "70e6c46f"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model\n",
        "\n",
        "1. Import `LogisticRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Implement the machine learning model with three different datasets:\n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b89f3d84",
      "metadata": {
        "id": "b89f3d84"
      },
      "source": [
        "## **Step 4:** Validate Model\n",
        "\n",
        "Calculate the training and validation accuracy for the three different tests implemented in Step 3"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "352106a3",
      "metadata": {
        "id": "352106a3"
      },
      "source": [
        "## **Step 5:** Visualize Results (4 marks for steps 3-5)\n",
        "\n",
        "1. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
        "2. Add the data size, training and validation accuracy for each dataset to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be4b5c0a",
      "metadata": {
        "id": "be4b5c0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5abc5f1-0d11-4ad2-8fd3-11700bd27b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Data Size  Training Accuracy  Validation Accuracy\n",
            "0     262200           0.926902             0.936957\n",
            "1       9200           0.614946             0.593478\n",
            "2      13110           0.940217             0.847826\n"
          ]
        }
      ],
      "source": [
        "# ADD YOUR CODE HERE FOR STEPS 3-5\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "# HINT: USING A LOOP TO STORE THE DATA IN YOUR RESULTS DATAFRAME WILL BE MORE EFFICIENT\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "logistic_model = LogisticRegression(max_iter = 2000, random_state = 0)\n",
        "\n",
        "# Created dictionary with dataset information\n",
        "datasets = {\"Full\": (X, y), \"First Two Columns\": (X.iloc[:, :2], y), \"Small\" : (X_small, y_small)}\n",
        "\n",
        "# Steps used for all 3 datasets: Split into train and test sets, fit the model, then calculate train and validation accuracies\n",
        "# Used hint to create loop to do tasks\n",
        "\n",
        "results = []\n",
        "for name, (X_set, y_set) in datasets.items():\n",
        "  # Split into train and test sets\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_set, y_set, test_size = 0.2, random_state = 0)\n",
        "\n",
        "  # Fit the model\n",
        "  logistic_model.fit(X_train, y_train)\n",
        "\n",
        "  # Calculate training accuracy\n",
        "  t_prediction = logistic_model.predict(X_train)\n",
        "  t_accuracy = accuracy_score(y_train, t_prediction)\n",
        "\n",
        "  # Calculate validation accuracy\n",
        "  v_prediction = logistic_model.predict(X_test)\n",
        "  v_accuracy = accuracy_score(y_test, v_prediction)\n",
        "\n",
        "  # Calculate data size\n",
        "  data_size = X_set.size\n",
        "\n",
        "  # Store results\n",
        "  results.append({\n",
        "        'Data Size': data_size,\n",
        "        'Training Accuracy': t_accuracy,\n",
        "        'Validation Accuracy': v_accuracy\n",
        "    })\n",
        "\n",
        "# Create dataframe of results\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(results_df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d4427d4f",
      "metadata": {
        "id": "d4427d4f"
      },
      "source": [
        "## **Questions (4 marks)**\n",
        "1. How do the training and validation accuracy change depending on the amount of data used? Explain with values.\n",
        "2. In this case, what do a false positive and a false negative represent? Which one is worse?\n",
        "\n",
        "<font color='Green'>\n",
        "  <b>\n",
        "    1. The full dataset shows a high training accuracy (~93%) along with the highest validation accuracy (~94%) out of the three datasets, which indicates that the larger the data size, the the higher the validation accuracy.  <br>\n",
        "    In the second situation where only the first two columns of data were used and the data size is the smallest, there is clearly not enough information about the different features of each email to make accurate predictions, resulting in the lowest training (~61%) and validation accuracy (~59%) metrics in the table. Also, the second model does almost equally well on its training and validation sets, which implies a high bias.  <br>\n",
        "    Despite the last dataset only containing 5% of the data, all columns are used which allows for more information about the features of each email and a high training accuracy (~94%); however, the data set is still quite small because of a limited number of email examples used, leading to a much lower validation accuracy (~85%). In addition, the fact that the third model did quite worse on the validation set than the training set indicates a higher variance and overfitting. <br> <br>\n",
        "  </b>\n",
        "  <b>\n",
        "    2. In this dataset which classifies emails as spam or non-spam, a false positive would represent a non-spam email that has been misclassified as spam, while a false negative would represent a spam email that has been misclassified as non-spam. I believe that false positives would be worse in spam detection because important emails that individuals are waiting for could be incorrectly classified as spam, which could be more impactful than simply letting spam emails into one's mailbox (false negatives).\n",
        "  </b>\n",
        "</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7559517a",
      "metadata": {
        "id": "7559517a"
      },
      "source": [
        "## **Process Description (4 marks)**\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59fe687f",
      "metadata": {
        "id": "59fe687f"
      },
      "source": [
        "<font color='Green'><b>DESCRIBE YOUR PROCESS HERE</b></font>\n",
        "\n",
        "> I referenced a few sources to come up with my code including the link provided to be able to use the load_spam() function, as well as notes given in labs 1, 2, and 3 to be able to import the appropriate libraries and use the train_test_split() and accuracy_score() functions. I also made sure to properly read the instructions given to create the LogisticRegression model. The isnull().any() function was referenced from the lab, and I remembered type() and size from past Python classes.\n",
        "\n",
        "> I completed the steps in the order provided because I believed it made the most sense.\n",
        "\n",
        "> I used generative AI, specifically ChatGPT, to help me fix an error when I was running my code after step 5, since I had written X[:,:2] instead of X.iloc[:,:2] to get the first two columns of the dataset. I simply prompted it to explain the error message to me, and I made the appropriate minor modifications to the code.\n",
        "\n",
        "> One challenge I faced was initially trying to find out how to calculate my training and validation accuracies; however, I looked through the lab 3 file and found the accuracy_score function which made it more clear. Overall, referencing the labs and reading the instructions helped me be successful.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fb4c78a8",
      "metadata": {
        "id": "fb4c78a8"
      },
      "source": [
        "# **Part 2: Regression (10.5 marks total)**\n",
        "\n",
        "For this section, we will be evaluating concrete compressive strength of different concrete samples, based on age and ingredients. You will need to repeat the steps 1-4 from Part 1 for this analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2ba83c5",
      "metadata": {
        "id": "b2ba83c5"
      },
      "source": [
        "## **Step 1:** Data Input (1 mark)\n",
        "\n",
        "The data used for this task can be downloaded using the yellowbrick library:\n",
        "https://www.scikit-yb.org/en/latest/api/datasets/concrete.html\n",
        "\n",
        "Use the yellowbrick function `load_concrete()` to load the spam dataset into the feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print the size and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ff2e34f",
      "metadata": {
        "id": "6ff2e34f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3f57ab6-75f6-48ba-d93b-103ebccf75e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of X: 8240\n",
            "Type of X: <class 'pandas.core.frame.DataFrame'>\n",
            "Size of y: 1030\n",
            "Type of y: <class 'pandas.core.series.Series'>\n"
          ]
        }
      ],
      "source": [
        "# Import spam dataset from yellowbrick library\n",
        "from yellowbrick.datasets import load_concrete\n",
        "\n",
        "# Load concrete dataset into the feature matrix X and target vector y\n",
        "X, y = load_concrete()\n",
        "\n",
        "# Print size and type of X and y\n",
        "print(\"Size of X:\", X.size)\n",
        "print(\"Type of X:\", type(X))\n",
        "print(\"Size of y:\", y.size)\n",
        "print(\"Type of y:\", type(y))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5294cfa",
      "metadata": {
        "id": "c5294cfa"
      },
      "source": [
        "## **Step 2:** Data Processing (0.5 marks)\n",
        "\n",
        "Check to see if there are any missing values in the dataset. If necessary, select an appropriate method to fill-in the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "693c5fa3",
      "metadata": {
        "id": "693c5fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1133a3-ff46-47bf-d800-76735677ba19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cement    False\n",
            "slag      False\n",
            "ash       False\n",
            "water     False\n",
            "splast    False\n",
            "coarse    False\n",
            "fine      False\n",
            "age       False\n",
            "dtype: bool\n"
          ]
        }
      ],
      "source": [
        "# Check if there are any missing values and fill them in if necessary\n",
        "missing_values = X.isnull().any()\n",
        "print(missing_values)\n",
        "\n",
        "# All values are False (no values are missing from any column) so no method to fill-in is necessary\n",
        "# If a number was missing, it could be filled with the mean value using the line below\n",
        "# X.fillna(X.mean(), inplace = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1bc60489",
      "metadata": {
        "id": "1bc60489"
      },
      "source": [
        "## **Step 3:** Implement Machine Learning Model (1 mark)\n",
        "\n",
        "1. Import `LinearRegression` from sklearn\n",
        "2. Instantiate model `LinearRegression()`.\n",
        "3. Implement the machine learning model with `X` and `y`"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "suiGuK-W1WnL"
      },
      "id": "suiGuK-W1WnL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5041945",
      "metadata": {
        "id": "b5041945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "495a0454-e2a8-4dc2-b729-7402a10c1761"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearRegression</label><div class=\"sk-toggleable__content\"><pre>LinearRegression()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "# ADD YOUR CODE HERE\n",
        "# Note: for any random state parameters, you can use random_state = 0\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Instantiate model\n",
        "linear_model = LinearRegression()\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
        "\n",
        "# Fit the model\n",
        "linear_model.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1de28482",
      "metadata": {
        "id": "1de28482"
      },
      "source": [
        "## **Step 4:** Validate Model (1 mark)\n",
        "\n",
        "Calculate the training and validation accuracy using mean squared error and R2 score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "970c038b",
      "metadata": {
        "id": "970c038b"
      },
      "outputs": [],
      "source": [
        "# ADD YOUR CODE HERE\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Calculate training mean squared error and R2 score\n",
        "t_prediction = linear_model.predict(X_train)\n",
        "t_mse = mean_squared_error(y_train, t_prediction)\n",
        "t_r2 = r2_score(y_train, t_prediction)\n",
        "\n",
        "# Calculate valiadtion mean squared error and R2 score\n",
        "v_prediction = linear_model.predict(X_test)\n",
        "v_mse = mean_squared_error(y_test, v_prediction)\n",
        "v_r2 = r2_score(y_test, v_prediction)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54aa7795",
      "metadata": {
        "id": "54aa7795"
      },
      "source": [
        "## **Step 5:** Visualize Results (1 mark)\n",
        "1. Create a pandas DataFrame `results` with columns: Training accuracy and Validation accuracy, and index: MSE and R2 score\n",
        "2. Add the accuracy results to the `results` DataFrame\n",
        "3. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88d223f3",
      "metadata": {
        "id": "88d223f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "750df56d-698d-469b-c4ff-68c5d032c58f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          Training accuracy  Validation accuracy\n",
              "MSE              110.345501            95.635335\n",
              "R2 score           0.609071             0.636898"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-09d7bdfa-479f-471c-80ba-e8366537be3c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training accuracy</th>\n",
              "      <th>Validation accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>MSE</th>\n",
              "      <td>110.345501</td>\n",
              "      <td>95.635335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>R2 score</th>\n",
              "      <td>0.609071</td>\n",
              "      <td>0.636898</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-09d7bdfa-479f-471c-80ba-e8366537be3c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-09d7bdfa-479f-471c-80ba-e8366537be3c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-09d7bdfa-479f-471c-80ba-e8366537be3c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-761246f0-61e0-4add-9c29-a0c9df683314\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-761246f0-61e0-4add-9c29-a0c9df683314')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-761246f0-61e0-4add-9c29-a0c9df683314 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_dc36fae3-3338-49ec-9fef-2d540d761ed7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('results')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_dc36fae3-3338-49ec-9fef-2d540d761ed7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('results');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "# ADD YOUR CODE HERE\n",
        "# Create results dataframe\n",
        "results = pd.DataFrame({\n",
        "    'Training accuracy': [t_mse, t_r2],\n",
        "    'Validation accuracy': [v_mse, v_r2]\n",
        "}, index = ['MSE', 'R2 score'])\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70a42bda",
      "metadata": {
        "id": "70a42bda"
      },
      "source": [
        "## **Questions (2 marks)**\n",
        "1. Did using a linear model produce good results for this dataset? Why or why not?\n",
        "\n",
        "No, the linear model did not produce good results for this dataset because the MSE values are quite high, indicating a large deviation between the actual and predicted values. Also, R2 scores are better when they are closer to 1, so the values calculated indicate that the model is not capturing the majority of the variance in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2ca0ff2f",
      "metadata": {
        "id": "2ca0ff2f"
      },
      "source": [
        "## **Process Description (4 marks)**\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dfdb0880",
      "metadata": {
        "id": "dfdb0880"
      },
      "source": [
        "<font color='Green'><b>Explain YOUR PROCESS here:</b></font>\n",
        "\n",
        "> I referenced a few sources when coming up with my code including the link provided to be able to use the load_concrete() function, as well as notes given in labs 1, 2, and 3 to be able to import the appropriate libraries and use the train_test_split() and accuracy_score() functions. I also made sure to properly read the instructions given to create the LinearRegression model. The isnull().any() function was referenced from the lab, and I remembered type() and size from past Python classes. The mean_squared_error function was provided in lab 3; however, I utilized scikit learn documentation to verify my use of the r2_score function (https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html).\n",
        "\n",
        "> I completed the steps in the order provided because I believed it made the most sense.\n",
        "\n",
        "> I used generative AI, specifically ChatGPT, to help me understand how to format my results DataFrame with indices since I had not done that in the previous part of this assignment, and I did not remember how to do it. I prompted it by asking how to specify indices when creating a DataFrame object in Python, and I modified the code to fit my specific requirements.\n",
        "\n",
        "> One challenge I faced was initially trying to find out how to calculate the mean_squared_error and r2_score values; however, I looked through the lab 3 file and found the mean_squared_error function and then I looked up the r2_score function to find out how to use them properly. Overall, referencing the labs and reading the instructions helped me be successful."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72ac3eb",
      "metadata": {
        "id": "e72ac3eb"
      },
      "source": [
        "# **Part 3: Observations/Interpretation (3 marks)**\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "<font color='Green'><b>\n",
        "  The main observation I had from Part 1 was the impact of data size on the accuracy scores. During lectures, we discussed that a logistic model is a type of linear model used when the output value is binary, and the findings in this assignment prove that linear models scale to very large datasets, which is shown based on the high accuracies when the full dataset was used (about 93% for the training set and about 94% for the validation set). In addition, it is clear that linear models perform well when the number of features is large compared to the number of samples, as the accuracies were much higher in the third case where only 5% of the samples were used and all the features were accounted (about 94% for the training set and about 85% for the validation set) for as opposed to the second case where only two features were used with the total number of samples (about 61% for the training set and about 59% for the validation set). <br> <br>\n",
        "\n",
        "  My main observation from the linear model in Part 2 was that linear models can be much less effective with smaller amounts of data. The full data size of the concrete set (8240) is much smaller than the data size from Part 1 of the spam data (262200), and the MSE and R2 scores calculated earlier (MSE values of ~110 for training and ~96 for validation with R2 scores of ~0.61 and ~0.64 respectively) clearly indicate that the linear model proved to be less effective for this set of data. These results support this weakness of linear models that was presented in class.\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40b84eed",
      "metadata": {
        "id": "40b84eed"
      },
      "source": [
        "# **Part 4: Reflection (2 marks)**\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "<font color='Green'><b>\n",
        "  I really liked being able to calculate and compare different regression metrics for real-life datasets in order to better understand which characteristics of a data set are most important when trying to create a model that is best suited for it. I found it interesting that the number of features plays a bigger role in creating a more accurate model than the number of samples, but it was challenging at times to figure out which python functions would show me the metrics I needed.\n",
        "</b></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db951b3a",
      "metadata": {
        "id": "db951b3a"
      },
      "source": [
        "# **Part 5: Bonus Question (4 marks)**\n",
        "\n",
        "Repeat Part 2 with Ridge and Lasso regression to see if you can improve the accuracy results. Which method and what value of alpha gave you the best R^2 score? Is this score \"good enough\"? Explain why or why not.\n",
        "\n",
        "**Remember**: Only test values of alpha from 0.001 to 100 along the logorithmic scale."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47623d44",
      "metadata": {
        "id": "47623d44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1024caac-7c6a-47f6-93c5-bf5b44a4e597"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Alpha  Training R2  Validation R2  Training MSE  Validation MSE\n",
            "0    0.001     0.609071       0.636898    110.345501       95.635335\n",
            "1    0.010     0.609071       0.636898    110.345501       95.635334\n",
            "2    0.100     0.609071       0.636898    110.345501       95.635324\n",
            "3    1.000     0.609071       0.636899    110.345501       95.635231\n",
            "4   10.000     0.609071       0.636902    110.345502       95.634301\n",
            "5  100.000     0.609071       0.636937    110.345597       95.625173\n",
            "\n",
            "\n",
            "Best Ridge R^2 Score:\n",
            "Alpha             100.000000\n",
            "Training R2         0.609071\n",
            "Validation R2       0.636937\n",
            "Training MSE      110.345597\n",
            "Validation MSE     95.625173\n",
            "Name: 5, dtype: float64\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "     Alpha  Training R2  Validation R2  Training MSE  Validation MSE\n",
            "0    0.001     0.609071       0.636899    110.345501       95.634971\n",
            "1    0.010     0.609071       0.636912    110.345507       95.631698\n",
            "2    0.100     0.609069       0.637034    110.346120       95.599545\n",
            "3    1.000     0.608852       0.638035    110.407340       95.335850\n",
            "4   10.000     0.602880       0.638874    112.093055       95.114791\n",
            "5  100.000     0.463736       0.521070    151.368492      126.142568\n",
            "\n",
            "\n",
            "Best Lasso R^2 Score:\n",
            "Alpha              10.000000\n",
            "Training R2         0.602880\n",
            "Validation R2       0.638874\n",
            "Training MSE      112.093055\n",
            "Validation MSE     95.114791\n",
            "Name: 4, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# ADD YOUR CODE HERE\n",
        "\n",
        "# Repeated from step 2 to ensure X and y are properly defined\n",
        "from yellowbrick.datasets import load_concrete\n",
        "X, y = load_concrete()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# First, importing Ridge and Lasso Regression tools\n",
        "from sklearn.linear_model import Ridge, Lasso\n",
        "\n",
        "# Created a list of alpha values from 0.001 to 100 along the logarithmic scale\n",
        "alpha_values = [0.001, 0.01, 0.1, 1, 10, 100]\n",
        "\n",
        "# Used Ridge Regression and calculated R2 score for different alpha values\n",
        "\n",
        "ridge_results = []\n",
        "\n",
        "for alpha in alpha_values:\n",
        "  ridge_model = Ridge(alpha = alpha)\n",
        "  ridge_model.fit(X_train, y_train)\n",
        "\n",
        "  t_prediction = ridge_model.predict(X_train)\n",
        "  t_r2 = r2_score(y_train, t_prediction)\n",
        "  t_mse = mean_squared_error(y_train, t_prediction)\n",
        "\n",
        "  v_prediction = ridge_model.predict(X_test)\n",
        "  v_r2 = r2_score(y_test, v_prediction)\n",
        "  v_mse = mean_squared_error(y_test, v_prediction)\n",
        "\n",
        "  ridge_results.append((alpha, t_r2, v_r2, t_mse, v_mse))\n",
        "\n",
        "ridge_data = pd.DataFrame(ridge_results, columns = ['Alpha', 'Training R2', 'Validation R2', 'Training MSE', 'Validation MSE'])\n",
        "print(ridge_data)\n",
        "print(\"\\n\")\n",
        "# Found alpha value with the highest validation R2 score\n",
        "best_ridge = ridge_data.loc[ridge_data['Validation R2'].idxmax()]\n",
        "\n",
        "print(\"Best Ridge R^2 Score:\")\n",
        "print(best_ridge)\n",
        "print(\"\\n\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# Used Lasso Regression and calculated R2 score for different alpha values\n",
        "\n",
        "lasso_results = []\n",
        "\n",
        "for alpha in alpha_values:\n",
        "  lasso_model = Lasso(alpha = alpha)\n",
        "  lasso_model.fit(X_train, y_train)\n",
        "\n",
        "  t_prediction = lasso_model.predict(X_train)\n",
        "  t_r2 = r2_score(y_train, t_prediction)\n",
        "  t_mse = mean_squared_error(y_train, t_prediction)\n",
        "\n",
        "  v_prediction = lasso_model.predict(X_test)\n",
        "  v_r2 = r2_score(y_test, v_prediction)\n",
        "  v_mse = mean_squared_error(y_test, v_prediction)\n",
        "\n",
        "  lasso_results.append((alpha, t_r2, v_r2, t_mse, v_mse))\n",
        "\n",
        "lasso_data = pd.DataFrame(lasso_results, columns = ['Alpha', 'Training R2', 'Validation R2','Training MSE', 'Validation MSE'])\n",
        "print(lasso_data)\n",
        "print(\"\\n\")\n",
        "# Found alpha value with the highest validation R2 score\n",
        "best_lasso = lasso_data.loc[lasso_data['Validation R2'].idxmax()]\n",
        "\n",
        "print(\"Best Lasso R^2 Score:\")\n",
        "print(best_lasso)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1b606236",
      "metadata": {
        "id": "1b606236"
      },
      "source": [
        "<font color='Green'><b>\n",
        "  The validation R2 score was improved in both cases compared to the linear model score calculated in part 2 (0.636898), but the Lasso regression model gave the best R2 validation score of 0.638874, with an alpha value of 10. This indicates that the Lasso model was able to more accurately predict unseen data in this set; however, the Ridge R2 score was higher for the training set, giving the same result as the linear model (0.609071), so Ridge might be fitting the data a bit more closely.\n",
        "  <br>\n",
        "  Ultimately, the lasso validation R2 score of 0.638874 is slightly higher than the other models, but all of the scores are in the range of 0.63-0.64, which indicates that about 63%-64% of the variation in the data is explained by these models. Whether or not this is good enough depends on what the required baseline performance of the model is for the purpose it is being used for. The scikit learn website describes concrete as the most important material in civil engineering, and the dataset being used predicts its compressive strength which could be vital for construction purposes; therefore, I would guess that the R2 score is not good enough, especially because it is not very close to 1, even though it entirely depends on what the experts consider \"good enough\" to be.\n",
        "</b></font>"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}